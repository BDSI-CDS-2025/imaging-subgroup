{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1ee0dc",
   "metadata": {},
   "source": [
    "# 11_model_zoo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bff88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Read in data from CSV files\n",
    "# Assuming the CSV files are located in a 'data/raw' directory relative to this script's location\n",
    "# Adjust the path as necessary based on your project structure\n",
    "path = Path.cwd().parent.parent\n",
    "img = pd.read_csv(path / \"data\" / \"raw\" / \"imagingFeatures.csv\")\n",
    "clin = pd.read_csv(path / \"data\" / \"raw\" / \"clinicalData_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b3847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the data- drop rows with NaN values\n",
    "TARGET = 'ER'\n",
    "data = img.merge(clin[['Patient ID', TARGET]], on='Patient ID', how='inner')\n",
    "data = data.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "data = data.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03c2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Select the target variable and merge with imaging data\n",
    "y = data[TARGET]\n",
    "\n",
    "# Encode target if needed\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Drop the target and patient ID columns to get the feature set\n",
    "X = data.drop([TARGET, 'Patient ID'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7e51",
   "metadata": {},
   "source": [
    "## Define search grids for RF, XGB, MLP\n",
    "A *search grid* is a set of hyperparameter values that are tested in order to find the optimal configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc38ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Categorical, Real, Integer # Required for MLPClassifier grid search\n",
    "\n",
    "# RandomForestClassifier search grid\n",
    "rf_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# XGBoost Classifier search grid\n",
    "xgb_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# MLPClassifier search grid\n",
    "mlp_grid = {\n",
    "    'hidden_layer_sizes': Integer(50, 100),  # Only single-layer, sizes 50 to 100\n",
    "    'activation': Categorical(['relu', 'tanh']),\n",
    "    'solver': Categorical(['adam', 'sgd']),\n",
    "    'alpha': Real(0.0001, 0.01, prior='log-uniform'),\n",
    "    'learning_rate_init': Real(0.001, 0.01, prior='log-uniform')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdce4a",
   "metadata": {},
   "source": [
    "## Bayesian search for efficient tuning\n",
    "* Each `BayesSearchCV` runs a Bayesian optimization over the respective hyperparameter grid\n",
    "* Uses cross-validation to evaluate each set of parameters\n",
    "* Attempts to find the best combination of hyperparameters that maximize the cross-validation score (in this case, accuracy)\n",
    "\n",
    "May need to run `pip install scikit-optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a0363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Bayesian optimization\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e31689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bayesian search for RandomForest\n",
    "rf_bayes = BayesSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    search_spaces=rf_grid,\n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Example: Bayesian search for XGBoost\n",
    "xgb_bayes = BayesSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    search_spaces=xgb_grid,\n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Example: Bayesian search for MLPClassifier\n",
    "mlp_bayes = BayesSearchCV(\n",
    "    estimator=MLPClassifier(max_iter=2000),\n",
    "    search_spaces=mlp_grid,\n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3e68f",
   "metadata": {},
   "source": [
    "## Fitting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577662ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#rf_bayes.fit(X, y)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#xgb_bayes.fit(X, y)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mlp_bayes\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/skopt/searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/skopt/searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 599\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step(\n\u001b[1;32m    600\u001b[0m         search_space,\n\u001b[1;32m    601\u001b[0m         optimizer,\n\u001b[1;32m    602\u001b[0m         score_name,\n\u001b[1;32m    603\u001b[0m         evaluate_candidates,\n\u001b[1;32m    604\u001b[0m         n_points\u001b[38;5;241m=\u001b[39mn_points_adjusted,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/skopt/searchcv.py:448\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    445\u001b[0m params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask(n_points\u001b[38;5;241m=\u001b[39mn_points)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    451\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/skopt/searchcv.py:448\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    445\u001b[0m params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask(n_points\u001b[38;5;241m=\u001b[39mn_points)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    451\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/skopt/searchcv.py:448\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    445\u001b[0m params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask(n_points\u001b[38;5;241m=\u001b[39mn_points)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    451\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "#rf_bayes.fit(X, y)\n",
    "#xgb_bayes.fit(X, y)\n",
    "mlp_bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98261fbd",
   "metadata": {},
   "source": [
    "### Understanding the models\n",
    "* RG = Random Forst\n",
    "* XBG = eXtreme Gradient Boosting: open source library that implements optimized distributed gradient boosting machine learning algorithms [(source)](https://www.nvidia.com/en-us/glossary/xgboost/)\n",
    "    * A scalable, distributed gradient-boosted decision tree (GBDT) machien learning library\n",
    "    * Provides parallel tree boosting\n",
    "    * GBDT: decision tree ensemble learning algorithm (consists of multiple decision trees, like random forest)\n",
    "* MLP = Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8917f",
   "metadata": {},
   "source": [
    "## Log results\n",
    "* `best_params_`: the best hyperparameters found\n",
    "* `best_score_`: the best cross-validation score (accuracy) achieved\n",
    "* `cv_results_`: more results for each of the hyperparameters tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384daf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def log_search_results(search, model_name, filename=\"cv_results.json\"):\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"best_score\": search.best_score_,\n",
    "        \"cv_results\": {\n",
    "            \"mean_test_score\": search.cv_results_[\"mean_test_score\"].tolist(),\n",
    "            \"std_test_score\": search.cv_results_[\"std_test_score\"].tolist(),\n",
    "            \"params\": search.cv_results_[\"params\"]\n",
    "        }\n",
    "    }\n",
    "    with open(filename, \"a\") as f:\n",
    "        json.dump(results, f)\n",
    "        f.write(\"\\n\")  # Write each result on a new line\n",
    "\n",
    "# Example usage after fitting:\n",
    "log_search_results(rf_bayes, \"RandomForest\")\n",
    "log_search_results(xgb_bayes, \"XGBoost\")\n",
    "#log_search_results(mlp_bayes, \"MLP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
